# ğŸ¦– DialoRaptor

Un chatbot conversationnel intelligent basÃ© sur la RAG (Retrieval-Augmented Generation) pour fournir des informations fiables sur le diabÃ¨te.

## ğŸ“‹ Table des matiÃ¨res

- [Description](#description)
- [FonctionnalitÃ©s](#fonctionnalitÃ©s)
- [Structure du projet](#structure-du-projet)
- [Installation](#installation)
- [Configuration](#configuration)
- [Utilisation](#utilisation)
- [Architecture technique](#architecture-technique)
- [Ã‰valuation](#Ã©valuation)
- [DonnÃ©es](#donnÃ©es)

---

## ğŸ“– Description

**DialoRaptor** est un systÃ¨me de chatbot informatif destinÃ© Ã  un organisme public, utilisant une approche RAG (Retrieval-Augmented Generation) pour rÃ©pondre Ã  des questions sur le diabÃ¨te avec prÃ©cision et pertinence. Le systÃ¨me combine :

- ğŸ” **Retrieval** : Recherche vectorielle sur une base de connaissances structurÃ©e
- ğŸ¤– **Augmented Generation** : GÃ©nÃ©ration de rÃ©ponses contextualisÃ©es via LLM
- ğŸ’¬ **Interface conversationnelle** : Chat interactif avec Chainlit

### âš ï¸ Avertissement Important
Ce chatbot est un **prototype informatif** et ne remplace en aucun cas un avis mÃ©dical professionnel. En cas de doute sur votre santÃ©, consultez un mÃ©decin.

---

## âœ¨ FonctionnalitÃ©s

- âœ… Questions-rÃ©ponses sur le diabÃ¨te basÃ©es sur une base de connaissance
- âœ… Recherche sÃ©mantique avec embeddings HuggingFace
- âœ… Interface chat en temps rÃ©el avec streaming
- âœ… Persistance des rÃ©sultats pour une performance optimisÃ©e
- âœ… MÃ©tadonnÃ©es de traÃ§abilitÃ© (source, sujet)
- âœ… Ã‰valuation des rÃ©ponses avec RAGAS

---

## ğŸ—‚ï¸ Structure du projet

```
dialociraptor/
â”œâ”€â”€ app.py                              # Application principale Chainlit
â”œâ”€â”€ build_index.py                      # Construction de l'index vectoriel
â”œâ”€â”€ Embedding.py                        # Gestion des embeddings
â”œâ”€â”€ evaluate_ragas.py                   # Ã‰valuation des rÃ©ponses
â”œâ”€â”€ chainlit.md                         # Configuration Chainlit
â”œâ”€â”€ requirements.txt                    # DÃ©pendances Python
â”œâ”€â”€ .env                                # Variables d'environnement (Ã  crÃ©er)
â”œâ”€â”€ README.md                           # Ce fichier
â”‚
â”œâ”€â”€ src/                                # DonnÃ©es source
â”‚   â”œâ”€â”€ corpus_diabete_clean.csv        # Corpus nettoyÃ© sur le diabÃ¨te
â”‚   â”œâ”€â”€ corpus_pdfs_clean.csv           # Corpus des PDFs
â”‚   â”œâ”€â”€ info_diabete - Feuille 1.csv    # Dataset de Q&A
â”‚   â””â”€â”€ recapitulatif_pdfs.md           # RÃ©sumÃ© des sources
â”‚
â”œâ”€â”€ data/                               # DonnÃ©es brutes (si nÃ©cessaire)
â”‚
â”œâ”€â”€ index_storage/                      # Index persistant
â”‚   â”œâ”€â”€ default__vector_store.json      # Store vectoriel
â”‚   â”œâ”€â”€ docstore.json                   # Documents
â”‚   â”œâ”€â”€ graph_store.json                # Graphe de connaissances
â”‚   â”œâ”€â”€ image__vector_store.json        # Images vectorisÃ©es
â”‚   â””â”€â”€ index_store.json                # Index
â”‚
â””â”€â”€ __pycache__/                        # Cache Python
```

---

## ğŸš€ Installation

### PrÃ©requis
- Python 3.10+
- pip ou conda
- Une clÃ© API 

### Ã‰tapes

#### 1. Cloner le projet
```bash
git clone <url-du-repo>
cd dialociraptor
```

#### 2. CrÃ©er un environnement virtuel
```bash
# Avec venv
python -m venv .venv

# Activation (Windows)
.venv\Scripts\activate

# Activation (Linux/Mac)
source .venv/bin/activate
```

#### 3. Installer les dÃ©pendances
```bash
pip install -r requirements.txt
```

#### 4. Configurer les variables d'environnement
CrÃ©er un fichier `.env` Ã  la racine du projet :

```env
OPENAI_API_KEY=gsk_xxxxxxxxxxxxx  
```

---

## âš™ï¸ Configuration

### ModÃ¨les utilisÃ©s

| Composant | ModÃ¨le | Provider |
|-----------|--------|----------|
| **Embeddings** | BAAI/bge-m3 | HuggingFace (local) |
| **LLM** | Llama 3.1 8B | Groq |
| **Interface** | - | Chainlit |

### ParamÃ¨tres ajustables

**Dans `app.py` :**
```python
Settings.llm = Groq(
    model="llama-3.1-8b-instant",
    temperature=0.1,              # â†“ pour plus de prÃ©cision, â†‘ pour plus de crÃ©ativitÃ©
    api_key=os.getenv("OPENAI_API_KEY")
)

query_engine = index.as_query_engine(
    streaming=True,
    similarity_top_k=3             # Nombre de documents Ã  rÃ©cupÃ©rer
)
```

---

## ğŸ’¬ Utilisation

### Lancer l'application

```bash
# Assurez-vous que l'environnement virtuel est activÃ©
chainlit run app.py -w
```

L'interface s'ouvre Ã  `http://localhost:8000`

### Workflow typique

1. **PremiÃ¨re utilisation** : ExÃ©cuter `build_index.py` pour crÃ©er l'index
   ```bash
   python build_index.py
   ```

2. **Lancer le chatbot**
   ```bash
   chainlit run app.py -w
   ```

3. **Poser des questions** sur le diabÃ¨te via l'interface

4. **Ã‰valuer les rÃ©sultats** avec RAGAS
   ```bash
   python evaluate_ragas.py
   ```

---

## ğŸ—ï¸ Architecture technique

### Pipeline RAG

```
User Query
    â†“
[Embedding Layer - BAAI/bge-m3]
    â†“
[Vector Search - VectorStore]
    â†“
[Top-K Retrieval (k=3)]
    â†“
[Context + Prompt Augmentation]
    â†“
[LLM Generation - Groq/Llama 3.1]
    â†“
[Streaming Response via Chainlit]
    â†“
User Display
```

### Composants clÃ©s

**`build_index.py`**
- Charge les donnÃ©es CSV
- CrÃ©e des objets Document avec mÃ©tadonnÃ©es
- Construit l'index vectoriel
- Persiste les donnÃ©es dans `./index_storage`

**`app.py`**
- Point d'entrÃ©e Chainlit
- Charge l'index persistant
- GÃ¨re les sessions utilisateur
- ExÃ©cute les requÃªtes en streaming

**`Embedding.py`**
- Utilitaires pour les embeddings
- Gestion des vecteurs

**`evaluate_ragas.py`**
- Ã‰valuation des rÃ©ponses via le framework RAGAS
- MÃ©triques de qualitÃ©

---

## ğŸ“Š Ã‰valuation

Le projet utilise **RAGAS** (Retrieval-Augmented Generation Assessment) pour Ã©valuer :

- **Faithfulness** : FidÃ©litÃ© de la rÃ©ponse au contexte
- **Answer Relevance** : Pertinence de la rÃ©ponse
- **Context Precision** : QualitÃ© du contexte rÃ©cupÃ©rÃ©

### Lancer l'Ã©valuation
```bash
python evaluate_ragas.py
```

---

## ğŸ“ DonnÃ©es

### Sources de donnÃ©es
- `corpus_diabete_clean.csv` : Corpus nettoyÃ© sur le diabÃ¨te
- `info_diabete - Feuille 1.csv` : Dataset de Q&A structurÃ©
  - Colonnes : `Question`, `Chunk_content`, `Source_ref`, `Topic`

### Format des mÃ©tadonnÃ©es
Chaque document contient :
- **source** : Source de rÃ©fÃ©rence (PDF, article, etc.)
- **topic** : CatÃ©gorie (symptÃ´mes, traitement, prÃ©vention, etc.)

---

## ğŸ”§ DÃ©pannage

### L'index n'est pas trouvÃ©
```bash
python build_index.py  # Reconstruire l'index
```

### Erreur de clÃ© API
- VÃ©rifier que le fichier `.env` existe
- VÃ©rifier que la clÃ© API est correcte
- RedÃ©marrer l'application

### RÃ©ponses de mauvaise qualitÃ©
- Augmenter `similarity_top_k` dans `app.py`
- Baisser la `temperature` pour plus de prÃ©cision
- VÃ©rifier la qualitÃ© des donnÃ©es source

---

## ğŸ“ Licence

[Ã€ remplir selon votre projet]

## ğŸ‘¥ Auteurs

- Anna Vitry (Development)

---

## ğŸ“š Ressources

- [LlamaIndex Documentation](https://docs.llamaindex.ai/)
- [Chainlit Documentation](https://docs.chainlit.io/)
- [Groq API](https://groq.com/docs/)
- [HuggingFace Embeddings](https://huggingface.co/)
- [RAGAS Framework](https://github.com/explodinggradients/ragas)
